{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19iKC7cfxObpAi3wc5i9XMRtAhk8sKxon","timestamp":1700520914247}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## In-Class Assignment: Data Modeling Process\n","\n","Use the [CDC Diabetes Health Indicators](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators) dataset to explore train/test splitting and regularization."],"metadata":{"id":"ZXOdG1EbSprY"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"erfrBkneRN_Z","executionInfo":{"status":"ok","timestamp":1702528616043,"user_tz":480,"elapsed":13224,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"outputs":[],"source":["pip install -q ucimlrepo"]},{"cell_type":"code","source":["from ucimlrepo import fetch_ucirepo\n","\n","cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n","\n","# data (as pandas dataframes)\n","X = cdc_diabetes_health_indicators.data.features\n","y = cdc_diabetes_health_indicators.data.targets"],"metadata":{"id":"bn3Nh2B2R0hC","executionInfo":{"status":"ok","timestamp":1702528617814,"user_tz":480,"elapsed":1781,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Determine two different reasonable methods to split or apply cross-validation to the data, based on the data attributes, distribution and task."],"metadata":{"id":"3WP9L-v5TFs4"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(max_iter=1000)"],"metadata":{"id":"NUW1q7panVdM","executionInfo":{"status":"ok","timestamp":1702528618759,"user_tz":480,"elapsed":947,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# method 1: train test split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=16)\n","model.fit(X_train, y_train)\n","model.predict(X_test)"],"metadata":{"id":"0RDStfc5R773","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702528650752,"user_tz":480,"elapsed":31995,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"1ef7aaf5-20d9-4e58-e2b6-319e8100e69c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 0, 0])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# method 2: k-fold cross-validation\n","from sklearn.model_selection import cross_val_score, KFold\n","\n","kfold = KFold(n_splits=5, shuffle=True, random_state=16)\n","results = cross_val_score(model, X, y, cv=kfold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Q0LHKWxk547","executionInfo":{"status":"ok","timestamp":1702528727963,"user_tz":480,"elapsed":77231,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"15b17b11-21b3-4952-e594-50c6f424e910"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]},{"cell_type":"markdown","source":["Identify what metrics you would recommend to use when evaluating and comparing machine learning models for this task.  How would you combine these metrics into a single metric?"],"metadata":{"id":"EtOUBIkdUCa8"}},{"cell_type":"code","source":["# I would use accuracy, precision, recall, and F-score to evaluate and compare models.\n","# I combine these metrics into a single metric using the function acc_fair.\n","\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def acc_fair(y, y_pred, lambda_val):\n","  acc = accuracy_score(y, y_pred)\n","  precision, recall, fscore, support = precision_recall_fscore_support(y, y_pred, average='binary', zero_division=True)\n","  fairness = 1 - np.abs(precision - recall)\n","\n","  acc_fair_score = acc - lambda_val * fairness\n","  return acc_fair_score"],"metadata":{"id":"aTKimCMCUdjM","executionInfo":{"status":"ok","timestamp":1702528727964,"user_tz":480,"elapsed":30,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["For one of the two methods you identified, run parameter search to find the \"best\" model, using the metric you defined."],"metadata":{"id":"SYrcO-K7TvaS"}},{"cell_type":"code","source":["# using method 1\n","\n","best_acc_fair_score = float('-inf')\n","best_threshold = 0\n","best_lambda = 0\n","\n","threshold = np.arange(0, 0.5, 0.01)\n","lambda_val = np.arange(0, 11, 1)\n","\n","copy = X_test.copy()\n","\n","for t in threshold:\n","  for l in lambda_val:\n","    pred_proba = model.predict_proba(copy)[:,1] >= t\n","    acc_fair_score = acc_fair(y_test, pred_proba, l)\n","\n","    if acc_fair_score > best_acc_fair_score:\n","      best_acc_fair_score = acc_fair_score\n","      best_threshold = t\n","      best_lambda = l\n","\n","print('Best Accuracy-Fairness Score:', best_acc_fair_score)\n","print('Best Threshold:', best_threshold)\n","print('Best Lambda Value:', best_lambda)"],"metadata":{"id":"ea6ot_GcR89D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702528749009,"user_tz":480,"elapsed":21050,"user":{"displayName":"Sophia Chung","userId":"18074224600171182532"}},"outputId":"4bf5c458-fc10-44d6-f8f8-7e6e32a53f68"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Accuracy-Fairness Score: 0.8656575212866604\n","Best Threshold: 0.49\n","Best Lambda Value: 0\n"]}]}]}